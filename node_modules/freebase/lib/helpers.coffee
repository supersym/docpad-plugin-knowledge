request = require("request")
async = require("async")
_ = require("underscore")
async_max = 10 #the hardest we will ever concurrently hit freebase

#non-front-facing methods that are used for the freebase javascript package
fns = {}

#originally by david huynh 2010, http://www.freebase.com/appeditor/#!path=//cubed.dfhuynh.user.dev/index
#Algorithm is adopted from
#http://www.csse.monash.edu.au/~damian/papers/HTML/Plurals.html
fns.singularize = (text) ->
  #multiple words
  
  # Table A.1
  
  # Table A.2
  # Table A.10
  
  # Table A.11
  
  # Table A.12
  
  # Table A.13
  
  # Table A.14
  
  # Table A.15
  
  # Table A.16
  
  # Table A.17
  
  # Table A.18
  
  # Table A.19
  
  # Table A.20
  
  # Table A.21
  
  # Table A.22
  
  # Table A.23
  
  # Table A.24
  
  # Table A.25
  suffix = (text, s) ->
    text.length >= s.length and text.substring(text.length - s.length) is s
  capIfCap = (s, s2) ->
    if typeof s is "string"
      isCap = s2.charAt(0).toLowerCase() isnt s2.charAt(0)
      (if isCap then (s.charAt(0).toUpperCase() + s.substr(1)) else s)
    else
      a = []
      for i of s
        s3 = s[i]
        a.push capIfCap(s3, s2)
      a
  inflection = (text, from, to) ->
    text.substring(0, text.length - from.length) + to
  isOneOf = (c, chars) ->
    chars.indexOf(c) >= 0
  isVowel = (c) ->
    isOneOf c, "aeiou"
  if text.match(" ")
    words = text.split(" ")
    last = words[words.length - 1]
    firsts = words.slice(0, -1)
    return firsts.join(" ") + " " + fns.singularize(last)
  prepositions =
    about: 1
    above: 1
    across: 1
    after: 1
    against: 1
    along: 1
    among: 1
    around: 1
    at: 1
    before: 1
    behind: 1
    below: 1
    beneath: 1
    beside: 1
    between: 1
    beyond: 1
    but: 1
    by: 1
    despite: 1
    down: 1
    during: 1
    except: 1
    for: 1
    from: 1
    in: 1
    inside: 1
    into: 1
    like: 1
    near: 1
    of: 1
    off: 1
    on: 1
    onto: 1
    out: 1
    outside: 1
    over: 1
    past: 1
    since: 1
    through: 1
    throughout: 1
    till: 1
    to: 1
    toward: 1
    under: 1
    underneath: 1
    until: 1
    up: 1
    upon: 1
    with: 1
    within: 1
    without: 1

  userDefinedNouns = [
    p: "people"
    s: "person"
  ,
    p: "tornadoes"
    s: "tornado"
  ,
    p: "churches"
    s: "church"
  ,
    p: "countries"
    s: "country"
  ,
    p: "cities"
    s: "city"
  ,
    p: "companies"
    s: "company"
  ,
    p: "monkies"
    s: "monkey"
  ,
    p: "donkies"
    s: "donkey"
  ,
    p: "mysteries"
    s: "mystery"
  ,
    p: "authors"
    s: "author"
  ]
  irregularNouns =
    beef:
      anglicized: "beefs"
      classical: "beeves"

    brother:
      anglicized: "brothers"
      classical: "brethren"

    child:
      anglicized: null
      classical: "children"

    cow:
      anglicized: null
      classical: "kine"

    ephemeris:
      anglicized: null
      classical: "ephemerides"

    genie:
      anglicized: null
      classical: "genii"

    money:
      anglicized: "moneys"
      classical: "monies"

    mongoose:
      anglicized: "mongooses"
      classical: null

    mythos:
      anglicized: null
      classical: "mythoi"

    octopus:
      anglicized: "octopuses"
      classical: "octopodes"

    ox:
      anglicized: null
      classical: "oxen"

    soliloquy:
      anglicized: "soliloquies"
      classical: null

    trilby:
      anglicized: "trilbys"
      classical: null

  uninflectedSuffixes = ["fish", "ois", "sheep", "deer", "pox", "itis"]
  uninflectedNouns =
    bison: 1
    flounder: 1
    pliers: 1
    bream: 1
    gallows: 1
    proceedings: 1
    breeches: 1
    graffiti: 1
    rabies: 1
    britches: 1
    headquarters: 1
    salmon: 1
    carp: 1
    herpes: 1
    scissors: 1
    chassis: 1
    "high-jinks": 1
    "sea-bass": 1
    seabass: 1
    clippers: 1
    homework: 1
    series: 1
    cod: 1
    innings: 1
    shears: 1
    contretemps: 1
    jackanapes: 1
    species: 1
    corps: 1
    mackerel: 1
    swine: 1
    debris: 1
    measles: 1
    trout: 1
    diabetes: 1
    mews: 1
    tuna: 1
    djinn: 1
    mumps: 1
    whiting: 1
    eland: 1
    news: 1
    wildebeest: 1
    elk: 1
    pincers: 1
    moose: 1
    shrimp: 1
    "hoi polloi": 1
    riffraff: 1
    rabble: 1

  inflectionCategories = [
    from: "a"
    to: "ae"
    words: ["alumna", "alga", "vertebra"]
  ,
    from: "a"
    anglicized: "as"
    classical: "ae"
    words: ["abscissa", "amoeba", "antenna", "aurora", "formula", "hydra", "hyperbola", "lacuna", "medusa", "nebula", "nova", "parabola"]
  ,
    from: "a"
    anglicized: "as"
    classical: "ata"
    words: ["anathema", "bema", "carcinoma", "charisma", "diploma", "dogma", "drama", "edema", "enema", "enigma", "gumma", "lemma", "lymphoma", "magma", "melisma", "miasma", "oedema", "sarcoma", "schema", "soma", "stigma", "stoma", "trauma"]
  ,
    from: "en"
    anglicized: "ens"
    classical: "ina"
    words: ["stamen", "foramen", "lumen"]
  ,
    from: "ex"
    to: "ices"
    words: ["codex", "murex", "silex"]
  ,
    from: "ex"
    anglicized: "exes"
    classical: "ices"
    words: ["apex", "cortex", "index", "latex", "pontifex", "simplex", "vertex", "vortex"]
  ,
    from: "is"
    anglicized: "ises"
    classical: "ides"
    words: ["iris", "clitoris"]
  ,
    from: "o"
    to: "os"
    words: ["albino", "archipelago", "armadillo", "commando", "ditto", "dynamo", "embryo", "fiasco", "generalissimo", "ghetto", "guano", "inferno", "jumbo", "lingo", "lumbago", "magneto", "manifesto", "medico", "octavo", "photo", "pro", "quarto", "rhino", "stylo"]
  ,
    from: "o"
    anglicized: "os"
    classical: "i"
    words: ["alto", "basso", "canto", "contralto", "crescendo", "solo", "soprano", "tempo"]
  ,
    from: "on"
    to: "a"
    words: ["aphelion", "asyndeton", "criterion", "hyperbaton", "noumenon", "organon", "perihelion", "phenomenon", "prolegomenon"]
  ,
    from: "um"
    to: "a"
    words: ["agendum", "bacterium", "candelabrum", "datum", "desideratum", "erratum", "extremum", "stratum", "ovum"]
  ,
    from: "um"
    anglicized: "ums"
    classical: "a"
    words: ["aquarium", "compendium", "consortium", "cranium", "curriculum", "dictum", "emporium", "enconium", "gymnasium", "honorarium", "interregnum", "lustrum", "maximum", "medium", "memorandum", "millenium", "minimum", "momentum", "optimum", "phylum", "quantum", "rostrum", "spectrum", "speculum", "stadium", "trapezium", "ultimatum", "vacuum", "velum"]
  ,
    from: "us"
    anglicized: "uses"
    classical: "i"
    words: ["focus", "fungus", "genius", "incubus", "nimbus", "nucleolus", "radius", "stylus", "succubus", "torus", "umbilicus", "uterus"]
  ,
    from: "us"
    anglicized: "uses"
    classical: "us"
    words: ["apparatus", "cantus", "coitus", "hiatus", "impetus", "nexus", "plexus", "prospectus", "sinus", "status"]
  ,
    from: ""
    to: "i"
    words: ["afreet", "afrit", "efreet"]
  ,
    from: ""
    to: "im"
    words: ["cherub", "goy", "geraph"]
  ]
  text2 = text.toLowerCase()
  for o of userDefinedNouns
    return userDefinedNouns[o].s  if userDefinedNouns[o].p is text
  for singular of irregularNouns
    entry = irregularNouns[singular]
    return capIfCap(singular, text)  if entry.anglicized is text2 or entry.classical is text2
  for s of uninflectedSuffixes
    return text  if suffix(text2, s)
  return text  if uninflectedNouns and uninflectedNouns[text2]
  checkWords = (from, to, words) ->
    if suffix(text, to)
      prefix = text.substring(text.length - to.length)
      text3 = prefix + entry.from
      for word of words
        return capIfCap(text3, text)  if text3 is word
    null

  for e of inflectionCategories
    entry = inflectionCategories[e]
    text3 = ("to" of entry and checkWords(entry.from, entry.to, entry.words)) or ("anglicized" of entry and checkWords(entry.from, entry.anglicized, entry.words)) or ("classical" of entry and checkWords(entry.from, entry.classical, entry.words))
    return text3  if text3? and typeof text3 is "string"
  for prep of prepositions
    n = text.indexOf(" " + prep + " ")
    if n > 0
      prefix = text.substring(0, n)
      r = singularize(prefix)
      if r?
        return r + " " + prep + " " + text.substr(n + prep.length + 2)
      else
        return null
    n = text.indexOf("-" + prep + "-")
    if n > 0
      prefix = text.substring(0, n)
      r = singularize(prefix)
      if r?
        return r + "-" + prep + "-" + text.substr(n + prep.length + 2)
      else
        return null
  j = text.lastIndexOf(" ")
  if j > 0
    r = singularize(text.substring(j + 1))
    if r?
      return text.substring(0, j + 1) + r
    else
      return null
  return text.substring(0, text.length - 2)  if suffix(text, "xes") or suffix(text, "ses")
  return text.substring(0, text.length - 1)  if suffix(text, "s") and not suffix(text, "ss")
  text


console.log fns.singularize "george soros"
console.log fns.singularize "mama cass"

#by spencer kelly (@spencermountain)
fns.sentenceparser = (text) ->
  tmp = text.split(/(\S.+?[.])(?=\s+|$)/g)
  sentences = []
  
  #join acronyms, titles
  for i of tmp
    if tmp[i]
      tmp[i] = tmp[i].replace(/^\s+|\s+$/g, "") #trim extra whitespace
      #join common abbreviations + acronyms
      if tmp[i].match(/(^| )(mr|dr|llb|md|bl|phd|ma|ba|mrs|miss|misses|mister|sir|esq|mstr|jr|sr|st|lit|inc|fl|ex|eg|jan|feb|mar|apr|jun|aug|sept?|oct|nov|dec)\. ?$/i) or tmp[i].match(/[ |\.][a-z]\.?$/i)
        tmp[parseInt(i) + 1] = tmp[i] + " " + tmp[parseInt(i) + 1]
      else
        sentences.push tmp[i]
        tmp[i] = ""
  
  #cleanup afterwards
  clean = []
  for i of sentences
    sentences[i] = sentences[i].replace(/^\s+|\s+$/g, "") #trim extra whitespace
    clean.push sentences[i]  if sentences[i]
  clean


console.log fns.sentenceparser('Dr. calm is me. lkj')

# remove objects with a duplicate field from json

fns.json_unique = (x, field) ->

  newArray = new Array()

  #label: for i < x.length

    #for j < newArray.length

      #if (newArray[j] && x[i] && newArray[j][field] == x[i][field]) continue label

  newArray[newArray.length] = x[i]
  newArray

#handle rate-limited asynchronous freebase calls with a ending callback
fns.doit_async = (arr, fn, options, done) ->

  #wrap them all in functions
  function_list = arr.map((r) ->
    (callback) ->
      fn r, options, (r) ->
        callback null, r

  )

  #groups of async tasks in a synchonous task
  all = fns.groups_of(function_list, async_max).map((f_group) ->
    (callback) ->
      async.parallel f_group, callback
  )
  async.series all, (err, result) ->

    #flatten it one level
    result = result.reduce((a, b) ->
      a.concat b
    )
    done result



#  quote a unicode string to turn it into a valid mql /type/key/value
fns.mql_encode = (s) ->

  return ""  unless s

  s = s.replace RegExp("  "), " "
  s = s.replace /^\s+|\s+$/, ""
  s = s.replace RegExp(" ", "g"), "_"

  mqlkey_start = "A-Za-z0-9"
  mqlkey_char = "A-Za-z0-9_-"

  MQLKEY_VALID = new RegExp("^[" + mqlkey_start + "][" + mqlkey_char + "]*$")
  MQLKEY_CHAR_MUSTQUOTE = new RegExp("([^" + mqlkey_char + "])", "g")
  # fastpath
  return s  if MQLKEY_VALID.exec(s)
  convert = (a, b) ->
    hex = b.charCodeAt(0).toString(16).toUpperCase()
    hex = "00" + hex  if hex.length is 2
    hex = "0" + hex  if hex.length is 3
    "$" + hex

  x = s.replace(MQLKEY_CHAR_MUSTQUOTE, convert)
  x = convert(x, x.charAt(0)) + x.substr(1)  if x.charAt(0) is "-" or x.charAt(0) is "_"
  x


#turn freebase's silly $00 encoding into unicode
fns.mql_unencode = (x) ->
  x = x.replace(/\$([0-9A-Fa-f]{4})/g, (a, b) ->
    String.fromCharCode parseInt(b, 16)
  )
  x


#console.log(fns.mql_unencode("K$00F6ppen_climate_classification"))

#turn an array into smaller groups of arrays
fns.groups_of = (arr, group_length) ->
  all = []
  for i of arr
    if i % group_length is 0
      all.push [arr[i]]
    else
      all[all.length - 1].push arr[i]
  all

fns.parseurl = (str) ->
  o =
    strictMode: false
    key: ["source", "protocol", "authority", "userInfo", "user", "password", "host", "port", "relative", "path", "directory", "file", "query", "anchor"]
    q:
      name: "queryKey"
      parser: /(?:^|&)([^&=]*)=?([^&]*)/g

    parser:
      strict: /^(?:([^:\/?#]+):)?(?:\/\/((?:(([^:@]*)(?::([^:@]*))?)?@)?([^:\/?#]*)(?::(\d*))?))?((((?:[^?#\/]*\/)*)([^?#]*))(?:\?([^#]*))?(?:#(.*))?)/
      loose: /^(?:(?![^:@]+:[^:@\/]*@)([^:\/?#.]+):)?(?:\/\/)?((?:(([^:@]*)(?::([^:@]*))?)?@)?([^:\/?#]*)(?::(\d*))?)(((\/(?:[^?#](?![^?#\/]*\.[^?#\/.]+(?:[?#]|$)))*\/?)?([^?#\/]*))(?:\?([^#]*))?(?:#(.*))?)/

  m = o.parser[(if o.strictMode then "strict" else "loose")].exec(str)
  uri = {}
  i = 14
  uri[o.key[i]] = m[i] or ""  while i--
  uri[o.q.name] = {}
  uri[o.key[12]].replace o.q.parser, ($0, $1, $2) ->
    uri[o.q.name][$1] = $2  if $1

  uri


#turn options object into get paramaters
fns.set_params = (options) ->
  return ""  unless options
  Object.keys(options).map((v) ->
    options[v] = encodeURIComponent(JSON.stringify(options[v]))  if _.isArray(options[v]) or _.isObject(options[v])
    v + "=" + options[v]
  ).join "&"

fns.http = (url, callback) ->
  return callback(error: "bad url")  unless url
  request
    uri: url
    headers:
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X x.y; rv:10.0) Gecko/20100101 Firefox/10.0"
  , (error, response, body) ->
    try
      body = JSON.parse(body)
    catch e
      return callback(error: e)
    return callback(error: error)  if error or response.statusCode isnt 200
    callback body


fns.isin = (word, arr) ->
  arr.some (v) ->
    v is word


module.exports = fns
